{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mrnd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Subset\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFolder\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataset import Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank Normalization\n",
    "\n",
    "### **get_ranked_list(similarity_measures)**\n",
    "\n",
    "This function ranks images based on the similarity measures between the target images and all other images.\n",
    "\n",
    "- Parameters similarity_measures:  Similarity measures between the target images and all other images.\n",
    "\n",
    "- Returns: A list of ranked images:  The format is the same as `similarity_measures`:   `[[ (image_index, similarity_measure), ...], ...]`.\n",
    "\n",
    "### **normalize_ranked_list(T)**\n",
    "\n",
    "This function normalizes the ranked list T by using the formula: normalized_value = 2 * L - (r_i_j + r_j_i)\n",
    "\n",
    "- Parameters T:  A list of ranked images, format: [[(image_index, weight), ...], ...]\n",
    "\n",
    "- Returns:\n",
    " A list of normalized ranked images:  The format is `normalized ranked images`:   `[[(image_index, normalized_weight), ...], ...]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranked_list(similarity_measures):\n",
    "    T = []\n",
    "    for row in similarity_measures:\n",
    "        rank_list = sorted(row, key=lambda x: x[1], reverse=True)\n",
    "        T.append(rank_list)\n",
    "    return T\n",
    "\n",
    "\n",
    "def normalize_ranked_list(T):\n",
    "    L = len(T)  # Number of images\n",
    "    normalized_T = [[] for _ in range(L)]\n",
    "    for i in range(L):\n",
    "        for j in range(L):\n",
    "            r_i_j = T[i][j][1]\n",
    "            r_j_i = T[j][i][1]\n",
    "            normalized_value = 2 * L - (r_i_j + r_j_i)\n",
    "            normalized_T[i].append((T[i][j][0], normalized_value))\n",
    "    return normalized_T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypergraph Construction\n",
    "This function creates the neighborhood set matrix N\n",
    "    :param T: Ranked list of images based on the weights\n",
    "    :param k: Number of images to be considered in the neighborhood set\n",
    "    :return: A neighborhood set, format (same as T): [[(image_index, weight), ...], ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neighborhood_set_matrix(T, k):\n",
    "    return [t[:k] for t in T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_continuous_incidence_matrix(N, k):\n",
    "    \"\"\"\n",
    "    Calculate the continuous incidence matrix H\n",
    "    :param N: the neighborhood set matrix N\n",
    "    :param k: the number of most similar images\n",
    "    :return: the continuous incidence matrix H\n",
    "    \"\"\"\n",
    "    H = np.zeros((len(N), len(N)))\n",
    "    for i in range(len(N)):\n",
    "        for (j, r_i_j) in N[i]:\n",
    "            H[i][j] = 1 - math.log(r_i_j, k + 1)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cartesian Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hyperedge_weight(q, H):\n",
    "    \"\"\"\n",
    "    Calculate the weight of a hyperedge\n",
    "    :param q: hyperedge index\n",
    "    :param H: continuous incidence matrix\n",
    "    :return: weight of the hyperedge\n",
    "    \"\"\"\n",
    "    w_e_q = 0\n",
    "    for i in range(len(H[q])):\n",
    "        w_e_q += H[q][i]\n",
    "    return w_e_q\n",
    "\n",
    "\n",
    "def calculate_pairwise_similarity_relationship(H, q, i, j):\n",
    "    \"\"\"\n",
    "    Calculate the pairwise similarity relationship between two images of a hyperedge\n",
    "    :param H: continuous incidence matrix\n",
    "    :param q: hyperedge index\n",
    "    :param i: first image index\n",
    "    :param j: second image index\n",
    "    :return: pairwise similarity relationship\n",
    "    \"\"\"\n",
    "    return calculate_hyperedge_weight(q, H) * H[q][i] * H[q][j]\n",
    "\n",
    "\n",
    "def calculate_cartesian_product(H):\n",
    "    \"\"\"\n",
    "    Calculate the Cartesian product C\n",
    "    :param H: continuous incidence matrix\n",
    "    :return: Cartesian product C\n",
    "    \"\"\"\n",
    "    C = np.zeros((len(H), len(H)))\n",
    "    for q in range(len(H)):\n",
    "        for i in range(len(H[q])):\n",
    "            for j in range(len(H[q])):\n",
    "                C[i][j] += calculate_pairwise_similarity_relationship(H, q, i, j)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pairwise_similarity_matrix(H):\n",
    "    \"\"\"\n",
    "    Calculate the pairwise similarity matrix S\n",
    "    :param H: continuous incidence matrix\n",
    "    :return: pairwise similarity matrix S\n",
    "    \"\"\"\n",
    "    H_transpose = H.T  # transpose of H\n",
    "    S_h = H @ H_transpose  # matrix multiplication H * H_transpose\n",
    "    S_v = H_transpose @ H  # matrix multiplication H_transpose * H\n",
    "    S = S_h * S_v  # element-wise multiplication (Hadamard product)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ΕΡΩΤΗΜΑ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_vectors(subset_dataset):\n",
    "    \"\"\"\n",
    "    Extract the feature vectors for all images in the subset dataset using the pre-trained ResNet-50 model\n",
    "    :param subset_dataset: the subset dataset\n",
    "    :return: the feature vectors for all images in the subset dataset\n",
    "    \"\"\"\n",
    "    # Load the pre-trained model\n",
    "    model = get_pretrained_model()\n",
    "\n",
    "    # Create a DataLoader for the subset dataset\n",
    "    # We set batch_size and num_workers based on our hardware resources\n",
    "    subset_loader = DataLoader(dataset=subset_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Move the model to the GPU if available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Compute the feature vectors for all images in the subset dataset using the pre-trained model\n",
    "    feature_vectors = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _ in subset_loader:\n",
    "            # Move the images to the appropriate device\n",
    "            images = images.to(device)\n",
    "            # Forward pass through the model to obtain feature vectors\n",
    "            outputs = model(images)\n",
    "            # Append the outputs to the feature_vectors list\n",
    "            feature_vectors.append(outputs)\n",
    "\n",
    "    # Concatenate the feature vectors into a single tensor\n",
    "    feature_vectors = torch.cat(feature_vectors, dim=0)\n",
    "\n",
    "    return feature_vectors\n",
    "\n",
    "\n",
    "def get_pretrained_model():\n",
    "    \"\"\"\n",
    "    Returns a pre-trained ResNet-50 model with the final layer removed\n",
    "    :return: the pre-trained model\n",
    "    \"\"\"\n",
    "    # Load the pre-trained model\n",
    "    model = models.resnet50(weights='ResNet50_Weights.DEFAULT')\n",
    "\n",
    "    # Replace the final layer with an empty Sequential module, so that we can obtain the feature vectors\n",
    "    model.fc = nn.Sequential()\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rnd\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataset import Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    \"\"\"\n",
    "    Load the dataset and return it\n",
    "    :return: the dataset\n",
    "    \"\"\"\n",
    "    # Define image transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize images to 224x224 pixels\n",
    "        transforms.ToTensor()  # Convert images to PyTorch tensors\n",
    "    ])\n",
    "\n",
    "    return ImageFolder(root='images', transform=transform)\n",
    "\n",
    "\n",
    "def get_subset_dataset(dataset):\n",
    "    \"\"\"\n",
    "    Create a subset from the dataset and return it\n",
    "    :param dataset: the dataset to create the subset from\n",
    "    :return: the subset dataset\n",
    "    \"\"\"\n",
    "    # Create a subset of the dataset\n",
    "    subset_size = 300  # Use 300 images as a subset\n",
    "    subset_indices = rnd.sample(range(len(dataset.imgs)), subset_size)  # Randomly sample subset_size indices\n",
    "    subset_dataset = Subset(dataset, subset_indices)\n",
    "    return subset_dataset\n",
    "\n",
    "\n",
    "def get_target_indices(subset_dataset):\n",
    "    \"\"\"\n",
    "    Randomly select 5 images from the subset as target images and return their indices\n",
    "    :param subset_dataset: the subset dataset\n",
    "    :return: the indices of the target images in the subset\n",
    "    \"\"\"\n",
    "    # Define the target images\n",
    "    no_of_images = 5  # Use 5 images as target images\n",
    "    subset_indices = list(range(len(subset_dataset)))\n",
    "    target_indices = [subset_indices.pop(rnd.randint(0, len(subset_indices) - 1)) for _ in\n",
    "                      range(no_of_images)]  # Randomly sample no_of_images indices\n",
    "    return target_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ερώτημα 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_measures(feature_vectors):\n",
    "    \"\"\"\n",
    "    Calculate the pairwise similarity measures for all images in the subset dataset\n",
    "    :param feature_vectors: the feature vectors of all images in the subset dataset\n",
    "    :return: the pairwise similarity measures ρ(o_i, o_j), format: [ [(j, similarity_measure), ...], ...],\n",
    "    where j is the index of the image in the subset dataset and similarity_measure is the pairwise similarity measure\n",
    "    \"\"\"\n",
    "    # Initialize a numpy array for the pairwise similarity measures\n",
    "    similarity_measures = []\n",
    "\n",
    "    # Compute the pairwise similarity measure between each target image and all other images\n",
    "    for i in range(len(feature_vectors)):\n",
    "        similarity_measures.append([])\n",
    "        for j in range(len(feature_vectors)):\n",
    "            similarity_measure = 1 / (np.linalg.norm(feature_vectors[i] - feature_vectors[j]) + 1)\n",
    "            similarity_measures[i].append((j, similarity_measure))\n",
    "    return similarity_measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_continuous_incidence_matrix(N, k):\n",
    "    \"\"\"\n",
    "    Calculate the continuous incidence matrix H\n",
    "    :param N: the neighborhood set matrix N\n",
    "    :param k: the number of most similar images\n",
    "    :return: the continuous incidence matrix H\n",
    "    \"\"\"\n",
    "    H = np.zeros((len(N), len(N)))\n",
    "    for i in range(len(N)):\n",
    "        for (j, r_i_j) in N[i]:\n",
    "            H[i][j] = 1 - math.log(r_i_j, k + 1)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-based Hypergraph of Ranking References (LHRR) Algorithm\n",
    "\n",
    "This function implements the Log-based Hypergraph of Ranking References (LHRR) algorithm.\n",
    "\n",
    "#### Parameters:\n",
    "- **T**:  \n",
    "  A collection of ranked images represented in the format:  \n",
    "  `[[ (image_index, weight), ...], ...]`.\n",
    "  \n",
    "- **iterations**:  \n",
    "  Specifies the total number of iterations to execute.\n",
    "\n",
    "#### Returns:\n",
    "- **A collection of ranked images**:  \n",
    "  Formatted as: `[[ (image_index, weight), ...], ...]`.\n",
    "  \n",
    "- **The total number of similar images**:  \n",
    "  Indicates the number of similar images analyzed within the neighborhood set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "def LHRR(T, iterations):\n",
    "    for iteration in range(iterations):\n",
    "        print(\"\\nStarting iteration \" + str(iteration + 1) + \"/\" + str(iterations) + \":\")\n",
    "\n",
    "        # Rank normalization\n",
    "        print(\"\\tNormalizing the ranked list T...\")\n",
    "        T = normalize_ranked_list(T)\n",
    "\n",
    "        # Create the neighborhood set matrix N\n",
    "        print(\"\\tCreating the neighborhood set matrix N...\")\n",
    "        k = 5  # k most similar images to consider in the neighborhood set\n",
    "        N = create_neighborhood_set_matrix(T, k)\n",
    "\n",
    "        # Calculate continuous incidence matrix H\n",
    "        print(\"\\tCalculating the continuous incidence matrix H...\")\n",
    "        H = calculate_continuous_incidence_matrix(N, k)\n",
    "\n",
    "        # Calculate the pairwise similarity matrix S\n",
    "        print(\"\\tCalculating the pairwise similarity matrix S...\")\n",
    "        S = calculate_pairwise_similarity_matrix(H)\n",
    "\n",
    "        # Calculate the Cartesian product C\n",
    "        print(\"\\tCalculating the Cartesian product C...\")\n",
    "        C = calculate_cartesian_product(H)\n",
    "\n",
    "        # Calculate the affinity matrix W\n",
    "        print(\"\\tCalculating the affinity matrix W...\")\n",
    "        W = C * S\n",
    "\n",
    "        # Update the ranked list T with the new weights\n",
    "        print(\"\\tUpdating the ranked list T with the new weights...\")\n",
    "        for i in range(len(W)):\n",
    "            for j in range(len(W[i])):\n",
    "                T[i][j] = (T[i][j][0], W[i][j])\n",
    "\n",
    "        # Sort the ranked list T\n",
    "        print(\"\\tSorting the ranked list T...\")\n",
    "        T = [sorted(t, key=lambda x: x[1], reverse=True) for t in T]\n",
    "    return T, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_weights_with_relevance(no_of_images, relevance_scores):\n",
    "    \"\"\"\n",
    "    Assign weights to the images based on their index and relevance scores\n",
    "    :param no_of_images: Number of images\n",
    "    :param relevance_scores: List of relevance scores\n",
    "    :return: List of weights\n",
    "    \"\"\"\n",
    "    return [relevance_scores[i] * (no_of_images - i) for i in range(no_of_images)]\n",
    "\n",
    "\n",
    "def show_images(target_image, subset_dataset, categories):\n",
    "    \"\"\"\n",
    "    Show a specific target image with the k most similar images and the accuracy of the algorithm\n",
    "    :param target_image: The target image with the k most similar images\n",
    "    :param subset_dataset: The subset dataset\n",
    "    :param categories: The categories names\n",
    "    \"\"\"\n",
    "    _, axs = plt.subplots(1, len(target_image), figsize=(14, 4))\n",
    "    plt.gcf().canvas.manager.set_window_title(f\"Target image {target_image[0][0]}\")\n",
    "\n",
    "    # Target image category\n",
    "    target_category_idx = subset_dataset.dataset.samples[subset_dataset.indices[target_image[0][0]]][1]\n",
    "\n",
    "    # Initialize the relevance scores\n",
    "    relevance_scores = []\n",
    "\n",
    "    # Iterate through the target images\n",
    "    for ax, (img_idx, score) in zip(axs, target_image):\n",
    "        # Retrieve the image from the dataset\n",
    "        image, _ = subset_dataset.dataset[subset_dataset.indices[img_idx]]\n",
    "\n",
    "        # Convert the image tensor to numpy array and transpose it\n",
    "        image = np.transpose(image.numpy(), (1, 2, 0))\n",
    "\n",
    "        # Plot the image\n",
    "        ax.imshow(image)\n",
    "\n",
    "        # Set the title of the image\n",
    "        category_idx = subset_dataset.dataset.samples[subset_dataset.indices[img_idx]][1]\n",
    "        category = categories[category_idx]\n",
    "        title = f'Category: {category}'\n",
    "        if img_idx == target_image[0][0]:\n",
    "            title += ' (target image)'\n",
    "        ax.set_title(title)\n",
    "\n",
    "        # Remove the axis\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Calculate the relevance score\n",
    "        score = 1 if category_idx == target_category_idx else 0\n",
    "        relevance_scores.append(score)\n",
    "\n",
    "    # Assign weights to the images based on their index and relevance scores\n",
    "    weights = assign_weights_with_relevance(len(target_image), relevance_scores)\n",
    "\n",
    "    # Get the accuracy of the algorithm based on the weights\n",
    "    accuracy = sum(weights) / sum(range(1, len(target_image) + 1))\n",
    "\n",
    "    # Show the accuracy on the plot\n",
    "    plt.suptitle(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "    # Show the images\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_target_images(T, target_indices, k):\n",
    "    \"\"\"\n",
    "    Get the target images from the ranked list\n",
    "    :param T: A list of ranked images, format: [[(image_index, weight), ...], ...]\n",
    "    :param target_indices: The indices of the target images in the subset\n",
    "    :param k: The number of similar images considered in the neighborhood set\n",
    "    :return: The target images with the k most similar images\n",
    "    \"\"\"\n",
    "    return [T[idx][:k] for idx in target_indices]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load the dataset\n",
    "    print(\"\\nFetching the dataset...\")\n",
    "    dataset = load_dataset()\n",
    "\n",
    "    # Create a subset of the dataset\n",
    "    print(\"Creating a subset of the dataset...\")\n",
    "    subset_dataset = get_subset_dataset(dataset)\n",
    "\n",
    "    # Get the indices of the target images in the subset dataset\n",
    "    print(\"Selecting the target images...\")\n",
    "    target_indices = get_target_indices(subset_dataset)\n",
    "\n",
    "    # Extract the feature vectors for all images in the subset dataset\n",
    "    print(\"Extracting the feature vectors...\")\n",
    "    feature_vectors = extract_feature_vectors(subset_dataset)\n",
    "\n",
    "    # Calculate the similarity measures for all images\n",
    "    print(\"Calculating the similarity measures...\")\n",
    "    similarity_measures = calculate_similarity_measures(feature_vectors)\n",
    "\n",
    "    # Rank the images based on the similarity measures\n",
    "    print(\"Ranking the images based on the similarity measures...\")\n",
    "    T = get_ranked_list(similarity_measures)\n",
    "\n",
    "    # Iterate through the main steps of the algorithm\n",
    "    T, k = LHRR(T, iterations=5)\n",
    "\n",
    "    # Get the target images from the ranked list\n",
    "    target_images = get_target_images(T, target_indices, k)\n",
    "\n",
    "    # Get all categories names from the dataset\n",
    "    categories = subset_dataset.dataset.classes\n",
    "\n",
    "    # Show the target images and the k most similar images\n",
    "    for target_image in target_images:\n",
    "        show_images(target_image, subset_dataset, categories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
